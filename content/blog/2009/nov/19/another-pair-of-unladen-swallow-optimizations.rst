
Another Pair of Unladen Swallow Optimizations
=============================================


Today a `patch of mine <http://code.google.com/p/unladen-swallow/source/detail?r=904>`_ was committed to Unladen Swallow.  In the past weeks I've described some of the optimizations that have gone into Unladen Swallow, in specific I looked at removing the allocation of an argument tuple for C functions.  One of the "on the horizon" things I mentioned was extending this to functions with a variable arity (that is the number of arguments they take can change).  This has been implemented for functions that take a finite range of argument numbers (that is, they don't take \*args, they just have a few arguments with defaults).  This support was used to optimize a number of builtin functions (dict.get, list.pop, getattr for example).

However, there were still a number of functions that weren't updated for this support.  I initially started porting any functions I saw, but it wasn't a totally mechanical translation so I decided to do a little profiling to better direct my efforts.  I started by using the cProfile module to see what functions were called most frequently in Unladen Swallow's Django template benchmark.  Imagine my surprise when I saw that unicode.encode was called over 300,000 times!  A quick look at that function showed that it was a perfect contender for this optimization, it was currently designated as a METH_VARARGS, but in fact it's argument count was a finite range.  After about of dozen lines of code, to change the argument parsing, I ran the benchmark again, comparing it a control version of Unladen Swallow, and it showed a consistent 3-6% speedup on the Django benchmark.  Not bad for 30 minutes of work.

Another optimization I want to look at, which hasn't landed yet, is one of optimize various operations.  Right now Unladen Swallow tracks various data about the types seen in the interpreter loop, however for various operators this data isn't actually used.  What this patch does is check at JIT compilation time whether the operator site is monomorphic (that is there is only one pair of types ever seen there), and if it is, and it is one of a few pairings that we have optimizations for (int + int, list[int], float - float for example) then optimized code is emitted.  This optimized code checks the types of both the arguments that they are the expected ones, if they are then the optimized code is executed, otherwise the VM bails back to the interpreter (various literature has shown that a single compiled optimized path is better than compiling both the fast and slow paths).  For simple algorithm code this optimization can show huge improvements.

The PyPy project has `recently blogged <http://morepypy.blogspot.com/2009/11/some-benchmarking.html>`_ about the results of the results of some benchmarks from the Computer Language Shootout run on PyPy, Unladen Swallow, and CPython.  In these benchmarks Unladen Swallow showed that for highly algorithmic code (read: mathy) it could use some work, hopefully patches like this can help improve the situation markedly.  Once this patch lands I'm going to rerun these benchmarks to see how Unladen Swallow improves, I'm also going to add in some of the more macro benchmarks Unladen Swallow uses to see how it compares with PyPy in those.  Either way, seeing the tremendous improvements PyPy and Unladen Swallow have over CPython gives me tremendous hope for the future.
